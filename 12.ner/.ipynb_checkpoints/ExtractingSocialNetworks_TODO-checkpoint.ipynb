{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the task of extracting social networks from text: for a given set of people mentioned in a text, can we extract a social network that connects them?  In this social network, people are the nodes, and the edges between them are weighted by the strength of their connection.  How you define what \"connection\" means here is up to you (within reason).\n",
    "\n",
    "This notebook requires networkx; install with:\n",
    "\n",
    "```sh\n",
    "pip install networkx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(filename):\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        data=file.read()\n",
    "        return nlp(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Pick an English-language book you know from [Project Gutenberg](https://www.gutenberg.org) and save it in the `data/` directory.  Read it in here.  From your own prior understanding of the book, what two characters in this work have a strong relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Treasure Island\n",
    "doc=process(\"../data/treasure_island.txt\")\n",
    "\n",
    "# I expect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your main task here will be to create a social network of people mentioned in text.  The `get_nodes` function is provided for you; this function returns a list of characters in a text along with a weight for them (their frequency of mention in the text).  You will need to implement `get_edges`, which should return a list of positive weights between those character nodes (if two characters do not have a tie between them, their weight is 0 and you don't have to include them in the edge list).\n",
    "\n",
    "The core question that you are answering here is how you measure whether a social tie exists between two characters in a text, and how you go about placing a weight on that edge that measures the strength of the tie. Two characters that have a strong tie should have a high weight.  Consider the different ways that we might measure social interaction in text -- the frequency with which two characters are mentioned together, how often they mention each other in dialogue, how \"friendly\" their interaction seems, etc.\n",
    "\n",
    "For two previous approaches to this, see Elson et al. (2010) \"[Extracting Social Networks from Literary Texts](http://www1.cs.columbia.edu/~delson/pubs/ACL2010-ElsonDamesMcKeown.pdf)\" and Stiller et al. 2003, \"[The Small World of Shakespeare's Plays](http://www.staff.ncl.ac.uk/daniel.nettle/shakespeare.pdf)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_people_mentions(doc, min_count=10):\n",
    "    \"\"\" Extract all of the PERSON mentions in a spacy-processed document.\n",
    "    Returns a dict mapping each unique person name to a list of spacy entity mentions\n",
    "    Each spacy entity has the following attributes:\n",
    "    \n",
    "    * text\n",
    "    * start position in document (character)\n",
    "    * end position in document (character)\n",
    "    * label (NER category)\n",
    "    \n",
    "    https://spacy.io/usage/linguistic-features#named-entities\n",
    "    \"\"\"\n",
    "    people=defaultdict(list)\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ == \"PERSON\":\n",
    "            people[entity.text.lstrip().rstrip()].append(entity)\n",
    "    \n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(people, min_count=10):\n",
    "    \"\"\" Creates network nodes from a dict of people mentions\n",
    "    Input: a dict of people mentions returned from get_people_mentions()\n",
    "    Output: a dict mapping the entity name to a positive numerical value of their importance \n",
    "    (the size of the node in a network graph)\n",
    "    \n",
    "    e.g., {\"Tom\": 5, \"Huck\": 1}\n",
    "    \n",
    "    \"\"\"\n",
    "    nodes=defaultdict(float)\n",
    "    total=0.\n",
    "    for person in people:\n",
    "        if len(people[person]) >= min_count:\n",
    "            nodes[person]=len(people[person])\n",
    "            total+=len(people[person])\n",
    "    \n",
    "    for person in nodes:\n",
    "        nodes[person]/=total\n",
    "    \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Before implementing `get_edges`, explain how you are defining a social tie, and how you are measuring it in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Implement `get_edges` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(people, doc):\n",
    "    \"\"\" Creates network edges from a dict of people mentions and the full spacy-processed document\n",
    "    Input: a dict of people mentions returned from get_people_mentions() and document returned from process()\n",
    "    Output: a dict mapping a person all of the other people they are connected to, along with the weight of\n",
    "    that connection.\n",
    "    \n",
    "    e.g., {\"Tom: {\"Huck\": 2, \"Sally\": 1}, \"Huck\": {\"Sally\": 1}}\n",
    "    \n",
    "    Keep in mind that doc gives you access to *all* of the tokens in the book.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    edges={}\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's map *mentions* of character to the unique individuals they refer to.  We'll talk about better ways of doing this when we get to coreference resolution in a couple of weeks, but for now let's make a simplification and just say that every mention with exactly the same form refers to the same individual (so all mentions of \"Elizabeth\" refer to the character ELIZABETH, all mentions of \"Mr. Darcy\" refer to MR. DARCY, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people=get_people_mentions(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create nodes in a network from this list of person mentions by weighting each unique person name by its frequency of occurrence (corresponding to the intuition that more frequently mentioned characters are more important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=get_nodes(people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll establish links between those nodes based on your operationalization within the `get_edges` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=get_edges(people, doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the network you've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(nodes, edges):\n",
    "\n",
    "    \"\"\" Plot a set of weighted nodes and weighted edges on a network graph \"\"\"\n",
    "    \n",
    "    # increase this to expand network\n",
    "    force_directed_expansion=2\n",
    "    \n",
    "    # increase these dimensions to make graph bigger\n",
    "    figure_height=20\n",
    "    figure_width=20\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for person in nodes:\n",
    "        G.add_node(person, nodesize=nodes[person])\n",
    "    for person1 in edges:\n",
    "        for person2 in edges[person1]:\n",
    "            if person1 in nodes and person2 in nodes:\n",
    "                G.add_weighted_edges_from([(person1, person2, edges[person1][person2]) ])\n",
    "\n",
    "    options = {\n",
    "    'edgecolors':\"black\",\n",
    "    'linewidths':1,\n",
    "    'with_labels': True,\n",
    "    'font_weight': 'regular',\n",
    "    }\n",
    "    \n",
    "    g_edges = G.edges()\n",
    "\n",
    "    sizes = [G.nodes[node]['nodesize']*100000 for node in G]\n",
    "    weights = [G[u][v]['weight']*10 for u,v in g_edges]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(figure_height, figure_width));\n",
    "\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, k=force_directed_expansion, iterations=100), node_size=sizes, width=weights, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_graph(nodes, edges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
