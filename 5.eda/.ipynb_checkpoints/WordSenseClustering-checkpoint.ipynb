{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc226e1",
   "metadata": {},
   "source": [
    "[Lucy and Bamman 2021](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00383/101877/Characterizing-English-Variation-across-Social) uses KMeans clustering over BERT representations to learn word senses in order to characterize their distinctive use within online communities.  In this notebook, we'll explore inferring distinct senses using clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778bb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0d8f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ebd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_for_token(string, term):\n",
    "    \n",
    "    # tokenize\n",
    "    inputs = tokenizer(string, return_tensors=\"pt\")\n",
    "    \n",
    "    # convert input ids to words\n",
    "    tokens=tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    \n",
    "    # find the first location of the query term among those tokens (so we know which BERT rep to use)\n",
    "    term_idx=tokens.index(term)\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # return the BERT rep for that token index\n",
    "    # The output is a pytorch tensor object, but let's convert it to a numpy object to work with numpy functions\n",
    "    \n",
    "    return outputs.last_hidden_state[0][term_idx].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6125829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            data.append(line.rstrip())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6507986",
   "metadata": {},
   "source": [
    "First, let's examine uses of the word \"cabinet\" from several contemporary novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05de50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_data(\"../data/cabinet.txt\")\n",
    "reps=[]\n",
    "for sentence in data:\n",
    "    reps.append(get_bert_for_token(sentence, \"cabinet\"))\n",
    "    \n",
    "# matrices for every word, using the term \"cabinet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f91ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e76f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tHe studiously ignored it as his fierce blue eyes swept around the cabinet room.\n",
      "0\tThe Englishman walked over to Murray’s cabinet and found a bottle of whiskey—a Christmas present, still unopened on New Year’s Eve.\n",
      "0\tShe opened the mirrored door to the medicine cabinet.\n",
      "0\tRoscoe nodded and the doctor got up and walked around to a file cabinet.\n",
      "0\tThe doctor stepped back to the cabinet and put the file away.\n",
      "0\tI heard her open this cabinet.\n",
      "0\tIn the china cabinet in the dining room, there was some china like the china Mrs. Hartley’s mother had owned.\n",
      "0\tExcept for the background noise of a tactical channel coming from a scanner on a file cabinet in the back, the place could have passed for a real estate office.\n",
      "0\tFour empty grass mats, a cabinet of supplies, all just sitting in the middle of this tunnel.\n",
      "0\tSo she goes in and while she’s running the water she looks through the cabinet below the sink, probably to see if there is anything worth lifting.\n",
      "1\tRyan had sailed through confirmation much more easily than Marcus Cabot, even easier than Bunker and Talbot, the President’s two star cabinet members.\n",
      "1\tThe cabinet met again in closed session, both ignoring and attending to the din outside their windows.\n",
      "1\tPresident Fowler might not have been terribly impressive, but he had selected superior cabinet officers and personal advisers.\n",
      "1\tCutter—or the appropriate cabinet secretary, each of whom was also an ASAO—would speak on background, and a story would be written in the major papers, allowing Congress and others to react to the idea before it was given an official presidential imprimatur.\n",
      "1\tA cabinet member and a Balkan king were mentioned in the same paragraph.\n"
     ]
    }
   ],
   "source": [
    "for idx in np.argsort(kmeans.labels_):\n",
    "    print(\"%s\\t%s\" % (kmeans.labels_[idx], data[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe2864",
   "metadata": {},
   "source": [
    "Now let's examine a word that has slightly more polysemy: *right*.  Explore clustering with different number of clusters; how many clusters do you need to settle on what you would consider to be the right number of distinct senses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1856ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_data(\"../data/right200.txt\")\n",
    "reps=[]\n",
    "for sentence in data:\n",
    "    reps.append(get_bert_for_token(sentence, \"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df1dbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebf22fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 5, 1: 5, 2: 5, 3: 5, 4: 5})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a6bbd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t\" Offers me , \" he went on , tapping his foot upon the floor , \" the little inheritance she is certain of so soon -- just as little and as much as I have wasted -- and begs and prays me to take it , set myself right with it , and remain in the service . \"\n",
      "0\t' Spend it , sir , ' says I. ' But I shall be taken in , ' he says , ' they wo n't give me the right change , I shall lose it , it 's no use to me . '\n",
      "0\tHe has more leisure for musing in Staple Inn and in the Rolls Yard during the long vacation than at other seasons , and he says to the two ' prentices , what a thing it is in such hot weather to think that you live in an island with the sea a-rolling and a-bowling right round you .\n",
      "0\tI must n't go into court and say , ' My Lord , I beg to know this from you -- is this right or wrong ?\n",
      "0\tShe went one way , and Jenny went another ; one went right to Lunnun , and t ' other went right from it .\n",
      "\n",
      "1\tOne might have supposed that the course was straight on -- over everything , neither to the right nor to the left , regardless of all considerations in the way , sparing nothing , treading everything under foot . \"\n",
      "1\tComes Mr. Snagsby in his black coat ; come the Chadbands ; come ( when the gorging vessel is replete ) the ' prentices and Guster , to be edified ; comes at last , with his slouching head , and his shuffle backward , and his shuffle forward , and his shuffle to the right , and his shuffle to the left , and his bit of fur cap in his muddy hand , which he picks as if it were some mangy bird he had caught and was plucking before eating raw , Jo , the very , very tough subject Mr. Chadband is to improve .\n",
      "1\tI have been at his right hand many a day when he was charging upon ruin full-gallop .\n",
      "1\tJo crosses and comes halting and shuffling up , slowly scooping the knuckles of his right hand round and round in the hollowed palm of his left , kneading dirt with a natural pestle and mortar .\n",
      "1\t\" My children , \" said Mr. Turveydrop , paternally encircling Caddy with his left arm as she sat beside him , and putting his right hand gracefully on his hip .\n"
     ]
    }
   ],
   "source": [
    "max_per_class=5\n",
    "cluster_counts=Counter()\n",
    "last_lab=None\n",
    "for idx in np.argsort(kmeans.labels_): # take the indices for all values that are 0, then 1\n",
    "    clusterID=kmeans.labels_[idx] # get the class, 0 or 1, for that first index\n",
    "    if cluster_counts[clusterID] < max_per_class: # if values in the cluster aren't 5 yet\n",
    "        cluster_counts[clusterID]+=1 # add 1 to the cluster\n",
    "        if clusterID != last_lab and last_lab is not None:\n",
    "            print()\n",
    "        last_lab=clusterID # max out when we have all the clusters\n",
    "        print(\"%s\\t%s\" % (clusterID, data[idx]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b317daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f02cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
