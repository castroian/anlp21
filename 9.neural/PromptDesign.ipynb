{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore few-shot learning with GPT-2.  While GPT-2 is a less expressive model than GPT-3 (and hence not as a good of a few shot learner), it can fit within the memory and processing constraints of laptops while also being openly available.  Can you create a new classification task and design prompts to differentiate between the classes within it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrIEtQc10uej"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzyR47bH7GSZ"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_prompt(prompt, labels):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    completion_layer = model(inputs).logits[:, -1, :]\n",
    "    probabilities = F.softmax(completion_layer, dim=-1)[0]\n",
    "    pred_idx=torch.argmax(probabilities)\n",
    "    pred_token = tokenizer.decode(pred_idx.tolist())\n",
    "\n",
    "    label_ids=[]\n",
    "    for label in labels:\n",
    "        token_ids=tokenizer.encode(label)\n",
    "        # token labels (e.g., Spanish, English) must be 1 token in length\n",
    "        assert len(token_ids) == 1\n",
    "        label_ids.append(token_ids[0])\n",
    "        \n",
    "    sorted_args=list(torch.argsort(probabilities[label_ids], descending=True))\n",
    "    for arg in sorted_args: \n",
    "            print(\"%.6f\\t%s\" % (probabilities[label_ids[arg]], labels[arg]))\n",
    "    \n",
    "    print(\"\\nCompletion with highest probability:\\n\")\n",
    "    print(prompt + pred_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"X: I love this movie\n",
    "Y: positive\n",
    "\n",
    "X: I hate the movie\n",
    "Y: negative\n",
    "\n",
    "X: I kind of like the movie\n",
    "Y: positive\n",
    "\n",
    "X: This is one of the best movies I've ever seen\n",
    "Y:\"\"\"\n",
    "\n",
    "classify_with_prompt(prompt, [\"positive\", \"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"X: Vampires take over the planet during an eclipse\n",
    "Y: Hor\n",
    "\n",
    "X: Two friends switch bodies and live each other's lives\n",
    "Y: Com\n",
    "\n",
    "X: John turns into a werewolf during a full moon\n",
    "Y: Hor\n",
    "\n",
    "X: John is a werewolf who plays basketball\n",
    "Y: Com\n",
    "\n",
    "X: A court sentences George to be Jerry's butler\n",
    "Y: Com\n",
    "\n",
    "X: A virus outbreak turns everyone into zombies\n",
    "Y:\"\"\"\n",
    "\n",
    "classify_with_prompt(prompt, [\"Hor\", \"Com\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Q: This is a text\n",
    "A: English\n",
    "\n",
    "Q: Nel mezzo del cammin' di nostra vita\n",
    "A: Italian\n",
    "\n",
    "Q: Je ne sais pas\n",
    "A:\"\"\"\n",
    "\n",
    "classify_with_prompt(prompt, [\"English\", \"Italian\", \"French\", \"Spanish\", \"Japanese\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**.  Your job is to create a new classification task using prompt design (as in the examples above).  You are free to consider binary classification or multiclass classifaction; keep in mind that you have ~1000 tokens to use as a prompt for GPT-2, so be sure to provide enough answered prompts for each class.  (Note it is not a requirement that your model performs *well* (we want to assess what is -- and isn't -- learnable) but give it every opportunity to do so.  Create 5 test examples to assess whether GPT-2 is able to recognize the class given your fixed prompt.  To take the language ID task above, one test example corresponds to one prediction you make for the same set of answered prompts; the following constitutes two test examples for that task:\n",
    "\n",
    "1.)\n",
    "\n",
    "```\n",
    "prompt = \"\"\"Q: This is a text\n",
    "A: English\n",
    "\n",
    "Q: Nel mezzo del cammin' di nostra vita\n",
    "A: Italian\n",
    "\n",
    "Q: Je ne sais pas\n",
    "A:\"\"\"\n",
    "```\n",
    "\n",
    "2.)\n",
    "\n",
    "``` \n",
    "prompt = \"\"\"Q: This is a text\n",
    "A: English\n",
    "\n",
    "Q: Nel mezzo del cammin' di nostra vita\n",
    "A: Italian\n",
    "\n",
    "Q: Non lo so\n",
    "A:\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "prompt_design",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
