{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thie notebook explores logistic regression and feedforward neural networks for binary text classification for your text classification problem, using the pytorch library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename, max_data_points=None):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for idx,line in enumerate(file):\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            label=cols[0]\n",
    "            text=cols[1]\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "\n",
    "    # shuffle the data\n",
    "    tmp = list(zip(X, Y))\n",
    "    random.shuffle(tmp)\n",
    "    X, Y = zip(*tmp)\n",
    "    \n",
    "    if max_data_points == None:\n",
    "        return X, Y\n",
    "    \n",
    "    return X[:max_data_points], Y[:max_data_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the directory with your data (from the CheckData_TODO.ipynb exercise).  \n",
    "# The directory should contain train.tsv, dev.tsv and test.tsv\n",
    "directory=\"../data/my_datasets/shortened\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll limit the training and dev data to 10,000 data points for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY=read_data(\"%s/train.tsv\" % directory, max_data_points=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "devX, devY=read_data(\"%s/dev.tsv\" % directory, max_data_points=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll represent the data using simple binary indicators of the most frequent 1000 words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, analyzer=str.split, lowercase=True, strip_accents=None, binary=True)\n",
    "X_train = vectorizer.fit_transform(trainX)\n",
    "X_dev = vectorizer.transform(devX)\n",
    "\n",
    "_,vocabSize=X_train.shape\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "\n",
    "Y_train=le.transform(trainY)\n",
    "Y_dev=le.transform(devY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=12):\n",
    "    batches_x=[]\n",
    "    batches_y=[]\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        batches_x.append(x[i:i+batch_size])\n",
    "        batches_y.append(y[i:i+batch_size])\n",
    "    \n",
    "    return batches_x, batches_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches_x, train_batches_y=get_batches(torch.from_numpy(X_train.todense()).float(), torch.LongTensor(Y_train))\n",
    "dev_batches_x, dev_batches_y=get_batches(torch.from_numpy(X_dev.todense()).float(), torch.LongTensor(Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y):\n",
    "\n",
    "    model.eval()\n",
    "    corr = 0.\n",
    "    total = 0.\n",
    "    with torch.no_grad():\n",
    "        for x, y in zip(x, y):\n",
    "            y_preds=model.forward(x)\n",
    "            for idx, y_pred in enumerate(y_preds):\n",
    "                prediction=torch.argmax(y_pred)\n",
    "                if prediction == y[idx]:\n",
    "                    corr += 1.\n",
    "                total+=1                          \n",
    "    return corr/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # torch.nn.Linear transforms an input of size input_dim (e.g., 1000 above) to an output of size output_dim (e.g., 2 classes for positive/negative)\n",
    "        self.linear1 = torch.nn.Linear(input_dim, output_dim) \n",
    "    \n",
    "    def forward(self, input): \n",
    "        x1 = self.linear1(input)\n",
    "\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN_1_Hidden_Layer(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_dim=100\n",
    "        # the first layer transforms an input of size input_dim (e.g., 1000 above) to an output of size hidden_dim (e.g., 100)\n",
    "        self.linear1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # the second layer transforms an input of size hidden_dim (e.g., 100) to an output of size output_dim (e.g., 2 classes for positive/negative)       \n",
    "        self.linear2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input): \n",
    "        # pass the input through the first layer\n",
    "        layer1_output = self.linear1(input)\n",
    "        \n",
    "        # pass that output through a non-linearity (here, tanh)\n",
    "        layer1_output = torch.tanh(layer1_output)\n",
    "        \n",
    "        # and then pass the output from that first layer as input to the second layer\n",
    "        layer2_output = self.linear2(layer1_output)\n",
    "\n",
    "        return layer2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_filename, train_batches_x, train_batches_y, dev_batches_x, dev_batches_y):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    losses = []\n",
    "    cross_entropy=nn.CrossEntropyLoss()\n",
    "\n",
    "    best_dev_acc=0.\n",
    "    \n",
    "    # we'll only train for 5 epochs for this exercise, but in practice you'd want to train for more\n",
    "    # (in general until you stop seeing improvements in accuracy on your *development* data)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "\n",
    "        for x, y in zip(train_batches_x, train_batches_y):\n",
    "            y_pred=model.forward(x)\n",
    "            loss = cross_entropy(y_pred.view(-1, 2), y.view(-1))\n",
    "            losses.append(loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        dev_accuracy=evaluate(model, dev_batches_x, dev_batches_y)\n",
    "        \n",
    "        # we're going to save the model that performs the best on *dev* data\n",
    "        if dev_accuracy > best_dev_acc:\n",
    "            torch.save(model.state_dict(), model_filename)\n",
    "            print(\"%.3f is better than %.3f, saving model ...\" % (dev_accuracy, best_dev_acc))\n",
    "            best_dev_acc = dev_accuracy\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n",
    "            \n",
    "    model.load_state_dict(torch.load(model_filename))            \n",
    "    print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))\n",
    "    return best_dev_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.467 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.467\n",
      "0.483 is better than 0.467, saving model ...\n",
      "Epoch 1, dev accuracy: 0.483\n",
      "Epoch 2, dev accuracy: 0.483\n",
      "Epoch 3, dev accuracy: 0.467\n",
      "Epoch 4, dev accuracy: 0.467\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.483\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegressionClassifier(1000, 2)\n",
    "dev_accuracy=train(logreg, \"logreg.model\", train_batches_x, train_batches_y, dev_batches_x, dev_batches_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.467 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.467\n",
      "0.500 is better than 0.467, saving model ...\n",
      "Epoch 1, dev accuracy: 0.500\n",
      "Epoch 2, dev accuracy: 0.500\n",
      "Epoch 3, dev accuracy: 0.450\n",
      "Epoch 4, dev accuracy: 0.450\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.500\n"
     ]
    }
   ],
   "source": [
    "ffnn1=FFNN_1_Hidden_Layer(1000, 2, hidden_dim=100)\n",
    "dev_accuracy=train(ffnn1, \"ffnn1.model\", train_batches_x, train_batches_y, dev_batches_x, dev_batches_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks converge to different solutions as a function of their *initialization* (the random choice of the initial values for parameters).  Let's train the `FFNN_1_Hidden_Layer` model 10 times and then plot the distribution of dev accuracies using [pandas.DataFrame.plot.density](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.density.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.450 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.450\n",
      "0.467 is better than 0.450, saving model ...\n",
      "Epoch 1, dev accuracy: 0.467\n",
      "Epoch 2, dev accuracy: 0.467\n",
      "Epoch 3, dev accuracy: 0.417\n",
      "Epoch 4, dev accuracy: 0.450\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.467\n",
      "0.500 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.500\n",
      "0.533 is better than 0.500, saving model ...\n",
      "Epoch 1, dev accuracy: 0.533\n",
      "Epoch 2, dev accuracy: 0.500\n",
      "Epoch 3, dev accuracy: 0.450\n",
      "Epoch 4, dev accuracy: 0.500\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.533\n",
      "0.483 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.483\n",
      "Epoch 1, dev accuracy: 0.467\n",
      "0.500 is better than 0.483, saving model ...\n",
      "Epoch 2, dev accuracy: 0.500\n",
      "Epoch 3, dev accuracy: 0.417\n",
      "Epoch 4, dev accuracy: 0.450\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.500\n",
      "0.450 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.450\n",
      "0.483 is better than 0.450, saving model ...\n",
      "Epoch 1, dev accuracy: 0.483\n",
      "0.533 is better than 0.483, saving model ...\n",
      "Epoch 2, dev accuracy: 0.533\n",
      "Epoch 3, dev accuracy: 0.433\n",
      "Epoch 4, dev accuracy: 0.450\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.533\n",
      "0.467 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.467\n",
      "0.500 is better than 0.467, saving model ...\n",
      "Epoch 1, dev accuracy: 0.500\n",
      "Epoch 2, dev accuracy: 0.467\n",
      "Epoch 3, dev accuracy: 0.450\n",
      "Epoch 4, dev accuracy: 0.450\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.500\n",
      "0.500 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.500\n",
      "Epoch 1, dev accuracy: 0.500\n",
      "0.517 is better than 0.500, saving model ...\n",
      "Epoch 2, dev accuracy: 0.517\n",
      "Epoch 3, dev accuracy: 0.433\n",
      "Epoch 4, dev accuracy: 0.467\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.517\n",
      "0.483 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.483\n",
      "Epoch 1, dev accuracy: 0.450\n",
      "Epoch 2, dev accuracy: 0.467\n",
      "Epoch 3, dev accuracy: 0.400\n",
      "Epoch 4, dev accuracy: 0.417\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.483\n",
      "0.500 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.500\n",
      "Epoch 1, dev accuracy: 0.467\n",
      "Epoch 2, dev accuracy: 0.483\n",
      "Epoch 3, dev accuracy: 0.450\n",
      "Epoch 4, dev accuracy: 0.450\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.500\n",
      "0.433 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.433\n",
      "0.467 is better than 0.433, saving model ...\n",
      "Epoch 1, dev accuracy: 0.467\n",
      "Epoch 2, dev accuracy: 0.467\n",
      "Epoch 3, dev accuracy: 0.400\n",
      "Epoch 4, dev accuracy: 0.417\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.467\n",
      "0.467 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.467\n",
      "0.483 is better than 0.467, saving model ...\n",
      "Epoch 1, dev accuracy: 0.483\n",
      "0.500 is better than 0.483, saving model ...\n",
      "Epoch 2, dev accuracy: 0.500\n",
      "Epoch 3, dev accuracy: 0.450\n",
      "Epoch 4, dev accuracy: 0.467\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.500\n"
     ]
    }
   ],
   "source": [
    "dev_accuracies=[]\n",
    "\n",
    "for i in range(10):\n",
    "    ffnn1=FFNN_1_Hidden_Layer(1000, 2, hidden_dim=100)\n",
    "    dev_accuracy=train(ffnn1, \"ffnn1.model\", train_batches_x, train_batches_y, dev_batches_x, dev_batches_y)\n",
    "    dev_accuracies.append(dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.DataFrame(dev_accuracies)\n",
    "ax = df.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding more layers to the FFNN below and experimenting with the dropout rate, hidden layer sizes, and different choices of non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN_Experiment(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=100):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dim=100\n",
    "        \n",
    "        # the first layer transforms an input of size input_dim (e.g., 1000 above) to an output of size hidden_dim (e.g., 100)\n",
    "        self.linear1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # a dropout layer randomly sets the output from the previous layer to 0 p% of the time\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        # the second layer transforms an input of size hidden_dim (e.g., 100) to an output of size output_dim (e.g., 2 classes for positive/negative)       \n",
    "        self.linear2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input): \n",
    "        # pass the input through the first layer\n",
    "        layer1_output = self.linear1(input)\n",
    "        \n",
    "        # pass that output through a non-linearity (here, tanh)\n",
    "        # alternatives include torch.relu and torch.sigmoid\n",
    "        layer1_output = torch.tanh(layer1_output)\n",
    "        \n",
    "        # then dropout some outputs during training time (not test time)\n",
    "        layer1_output=self.dropout(layer1_output)\n",
    "        \n",
    "        # and then pass the output from that first layer as input to the second layer\n",
    "        layer2_output = self.linear2(layer1_output)\n",
    "\n",
    "        return layer2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835 is better than 0.000, saving model ...\n",
      "Epoch 0, dev accuracy: 0.835\n",
      "Epoch 1, dev accuracy: 0.834\n",
      "Epoch 2, dev accuracy: 0.832\n",
      "Epoch 3, dev accuracy: 0.832\n",
      "Epoch 4, dev accuracy: 0.832\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.835\n"
     ]
    }
   ],
   "source": [
    "ffnn_e=FFNN_Experiment(1000, 2, hidden_dim=100)\n",
    "dev_accuracy=train(ffnn_e, \"ffnn_e.model\", train_batches_x, train_batches_y, dev_batches_x, dev_batches_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier_unigram_bigram(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    CNN over window sizes of 1 (unigrams) and 2 (bigrams) each 96 filters, where a document\n",
    "    is representated as the concatentation of the 96 ungram filters + 96 bigram filters.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, pretrained_embeddings):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_filters=96\n",
    "        \n",
    "        self.num_labels = 2\n",
    "\n",
    "        _, embedding_dim=pretrained_embeddings.shape\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "\n",
    "        # convolution over 1 word\n",
    "        self.conv_1 = nn.Conv1d(embedding_dim, self.num_filters, 1, 1)\n",
    "\n",
    "        # convolution over 2 words    \n",
    "        self.conv_2 = nn.Conv1d(embedding_dim, self.num_filters, 2, 1)\n",
    "\n",
    "        self.fc = nn.Linear(self.num_filters*2, self.num_labels)\n",
    "\n",
    "    \n",
    "    def forward(self, input): \n",
    "        \n",
    "        # batch_size x max_seq_length x embeddings_size\n",
    "        x0 = self.embeddings(input)\n",
    "        \n",
    "        # batch_size x embeddings_size x max_seq_length\n",
    "        # (the input order expected by nn.Conv1d)\n",
    "        x0 = x0.permute(0, 2, 1)\n",
    "\n",
    "        # convolution\n",
    "        x1 = self.conv_1(x0)\n",
    "        # non-linearity\n",
    "        x1 = torch.tanh(x1)\n",
    "        # global max-pooling over the entire sequence\n",
    "        x1=torch.max(x1, 2)[0]\n",
    "\n",
    "        x2 = self.conv_2(x0)\n",
    "        x2 = torch.tanh(x2)\n",
    "        x2=torch.max(x2, 2)[0]\n",
    "\n",
    "        combined=torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        out = self.fc(combined)\n",
    "        \n",
    "        return out        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
